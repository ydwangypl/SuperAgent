#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
SuperAgent è¯¦ç»†åŠŸèƒ½æµ‹è¯•ä¸è¦†ç›–ç‡åˆ†æ

åŒ…æ‹¬:
1. å•å…ƒæµ‹è¯•
2. é›†æˆæµ‹è¯•
3. åŠŸèƒ½æµ‹è¯•
4. æ€§èƒ½æµ‹è¯•
5. å®‰å…¨æµ‹è¯•
"""

import sys
import time
import json
import asyncio
from pathlib import Path
from typing import Dict, Optional
from datetime import datetime

SUPERAGENT_ROOT = Path(__file__).parent
sys.path.insert(0, str(SUPERAGENT_ROOT))


class DetailedTestRunner:
    """è¯¦ç»†æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_tests": 0,
                "passed": 0,
                "failed": 0,
                "skipped": 0,
                "coverage": {}
            },
            "modules": {},
            "integration_tests": {},
            "performance_tests": {},
            "security_tests": {},
            "issues": [],
            "recommendations": []
        }

    def log(self, message: str, level: str = "INFO"):
        """è®°å½•æ—¥å¿—"""
        icon = {
            "INFO": "[INFO]",
            "SUCCESS": "[PASS]",
            "ERROR": "[FAIL]",
            "WARNING": "[WARN]",
            "TEST": "[TEST]"
        }.get(level, "[LOG]")
        try:
            print(f"{icon} {message}")
        except UnicodeEncodeError:
            print(f"{icon} {message.encode('utf-8', 'ignore').decode('utf-8')}")

    # ========================================================================
    # æ¨¡å—æµ‹è¯•
    # ========================================================================

    def test_module(self, module_name: str, import_path: str) -> Dict:
        """æµ‹è¯•å•ä¸ªæ¨¡å—"""
        self.log(f"æµ‹è¯•æ¨¡å—: {module_name}", "TEST")
        result = {
            "module": module_name,
            "import_path": import_path,
            "import_success": False,
            "classes": [],
            "functions": [],
            "tests_run": 0,
            "tests_passed": 0,
            "tests_failed": 0,
            "errors": []
        }

        try:
            # å°è¯•å¯¼å…¥æ¨¡å—
            parts = import_path.split('.')
            module = __import__(import_path)
            for part in parts[1:]:
                module = getattr(module, part)

            result["import_success"] = True
            self.log(f"  [PASS] æ¨¡å—å¯¼å…¥æˆåŠŸ", "SUCCESS")

            # æ£€æŸ¥ç±»
            import inspect
            for name, obj in inspect.getmembers(module, inspect.isclass):
                if obj.__module__ == import_path:
                    result["classes"].append(name)
                    self.log(f"    - ç±»: {name}", "INFO")

            # æ£€æŸ¥å‡½æ•°
            for name, obj in inspect.getmembers(module, inspect.isfunction):
                if obj.__module__ == import_path:
                    result["functions"].append(name)
                    self.log(f"    - å‡½æ•°: {name}", "INFO")

        except Exception as e:
            result["errors"].append(str(e))
            self.log(f"  [FAIL] æ¨¡å—å¯¼å…¥å¤±è´¥: {e}", "ERROR")

        return result

    def test_all_modules(self):
        """æµ‹è¯•æ‰€æœ‰æ¨¡å—"""
        self.log("\n" + "="*80, "INFO")
        self.log("æ¨¡å—æµ‹è¯•".center(80), "INFO")
        self.log("="*80 + "\n", "INFO")

        modules_to_test = {
            "CLI": "cli.main",
            "Conversation Manager": "conversation.manager",
            "Intent Recognizer": "conversation.intent_recognizer",
            "Project Planner": "planning.planner",
            "Step Generator": "planning.step_generator",
            "Dependency Analyzer": "planning.dependency_analyzer",
            "Smart Planner": "planning.smart_planner",
            "Orchestrator": "orchestration.orchestrator",
            "Task Scheduler": "orchestration.scheduler",
            "Agent Dispatcher": "orchestration.agent_dispatcher",
            "Review Orchestrator": "orchestration.review_orchestrator",
            "Base Agent": "execution.base_agent",
            "Coding Agent": "execution.coding_agent",
            "Testing Agent": "execution.testing_agent",
            "Documentation Agent": "execution.documentation_agent",
            "Refactoring Agent": "execution.refactoring_agent",
            "Agent Output Builder": "execution.agent_output_builder",
            "Memory Manager": "memory.memory_manager",
            "Code Reviewer": "review.reviewer",
            "Ralph Wiggum": "review.ralph_wiggum",
            "Error Recovery": "orchestration.error_recovery",
            "Token Monitor": "monitoring.token_monitor",
            "Smart Compressor": "context.smart_compressor",
            "Incremental Updater": "context.incremental_updater",
            "Worktree Manager": "orchestration.worktree_manager",
            "Distributed Executor": "orchestration.distributed_executor",
        }

        for module_name, import_path in modules_to_test.items():
            result = self.test_module(module_name, import_path)
            self.results["modules"][module_name] = result

            if result["import_success"]:
                self.results["summary"]["passed"] += 1
            else:
                self.results["summary"]["failed"] += 1
                self.results["issues"].append({
                    "type": "module_import",
                    "module": module_name,
                    "error": result["errors"][0] if result["errors"] else "Unknown error"
                })

            self.results["summary"]["total_tests"] += 1

    # ========================================================================
    # é›†æˆæµ‹è¯•
    # ========================================================================

    async def test_conversation_flow(self):
        """æµ‹è¯•å¯¹è¯æµç¨‹"""
        self.log("\næµ‹è¯•å¯¹è¯æµç¨‹é›†æˆ", "TEST")
        result = {
            "test": "conversation_flow",
            "status": "failed",
            "steps": [],
            "errors": []
        }

        try:
            from conversation.manager import ConversationManager

            # åˆå§‹åŒ–
            mgr = ConversationManager()
            result["steps"].append("åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨")
            _ = mgr  # æ ‡è®°ä¸ºå·²ä½¿ç”¨
            self.log("  [PASS] å¯¹è¯ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ", "SUCCESS")

            # æµ‹è¯•è¾“å…¥å¤„ç†
            test_inputs = [
                "åˆ›å»ºä¸€ä¸ªåšå®¢ç³»ç»Ÿ",
                "æ·»åŠ ç”¨æˆ·è®¤è¯åŠŸèƒ½",
                "ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"
            ]

            for input_text in test_inputs:
                try:
                    await mgr.process_input(input_text)
                    result["steps"].append(f"å¤„ç†è¾“å…¥: {input_text}")
                    self.log(f"  [PASS] å¤„ç†è¾“å…¥: {input_text}", "SUCCESS")
                except Exception as e:
                    result["errors"].append(f"å¤„ç†è¾“å…¥å¤±è´¥: {e}")
                    self.log(f"  [FAIL] å¤„ç†è¾“å…¥å¤±è´¥: {e}", "ERROR")

            result["status"] = "passed"

        except Exception as e:
            result["errors"].append(str(e))
            self.log(f"  [FAIL] å¯¹è¯æµç¨‹æµ‹è¯•å¤±è´¥: {e}", "ERROR")

        self.results["integration_tests"]["conversation_flow"] = result
        return result

    async def test_planning_flow(self):
        """æµ‹è¯•è§„åˆ’æµç¨‹"""
        self.log("\næµ‹è¯•è§„åˆ’æµç¨‹é›†æˆ", "TEST")
        result = {
            "test": "planning_flow",
            "status": "failed",
            "steps": [],
            "errors": []
        }

        try:
            from planning.planner import ProjectPlanner

            # åˆå§‹åŒ–
            planner = ProjectPlanner()
            result["steps"].append("åˆå§‹åŒ–è§„åˆ’å™¨")
            _ = planner  # æ ‡è®°ä¸ºå·²ä½¿ç”¨
            self.log("  [PASS] è§„åˆ’å™¨åˆå§‹åŒ–æˆåŠŸ", "SUCCESS")

            # æµ‹è¯•è®¡åˆ’åˆ›å»º
            test_requirements = [
                "åˆ›å»ºä¸€ä¸ªç®€å•çš„åšå®¢ç³»ç»Ÿ",
                "å¼€å‘ä¸€ä¸ªç”µå•†ç½‘ç«™",
                "æ„å»ºä¸€ä¸ªAPIæœåŠ¡"
            ]

            for req in test_requirements:
                try:
                    plan = await planner.create_plan(req, {})
                    result["steps"].append(f"åˆ›å»ºè®¡åˆ’: {req}")
                    self.log(f"  [PASS] åˆ›å»ºè®¡åˆ’: {req}", "SUCCESS")

                    # æ£€æŸ¥è®¡åˆ’ç»“æ„
                    if hasattr(plan, 'steps'):
                        result["steps"].append(f"  ç”Ÿæˆ {len(plan.steps)} ä¸ªæ­¥éª¤")
                        self.log(f"    ç”Ÿæˆ {len(plan.steps)} ä¸ªæ­¥éª¤", "INFO")

                except Exception as e:
                    result["errors"].append(f"è®¡åˆ’åˆ›å»ºå¤±è´¥: {e}")
                    self.log(f"  [FAIL] è®¡åˆ’åˆ›å»ºå¤±è´¥: {e}", "ERROR")

            result["status"] = "passed"

        except Exception as e:
            result["errors"].append(str(e))
            self.log(f"  [FAIL] è§„åˆ’æµç¨‹æµ‹è¯•å¤±è´¥: {e}", "ERROR")

        self.results["integration_tests"]["planning_flow"] = result
        return result

    async def test_agent_registry(self):
        """æµ‹è¯•Agentæ³¨å†Œä¸­å¿ƒ"""
        self.log("\næµ‹è¯•Agentæ³¨å†Œä¸­å¿ƒ", "TEST")
        result = {
            "test": "agent_registry",
            "status": "failed",
            "steps": [],
            "errors": []
        }

        try:
            from orchestration.registry import AgentRegistry

            # åˆå§‹åŒ–
            AgentRegistry.initialize()
            result["steps"].append("åˆå§‹åŒ–Agentæ³¨å†Œä¸­å¿ƒ")
            self.log("  [PASS] Agentæ³¨å†Œä¸­å¿ƒåˆå§‹åŒ–æˆåŠŸ", "SUCCESS")

            # æ£€æŸ¥æ³¨å†Œçš„Agent
            agents = AgentRegistry.list_agents()
            result["steps"].append(f"å·²æ³¨å†Œ {len(agents)} ä¸ªAgent")
            self.log(f"  [PASS] å·²æ³¨å†Œ {len(agents)} ä¸ªAgent:", "SUCCESS")

            for agent_name, agent_info in agents.items():
                self.log(f"    - {agent_name}: {agent_info.get('description', 'No description')}", "INFO")

            result["status"] = "passed"

        except Exception as e:
            result["errors"].append(str(e))
            self.log(f"  [FAIL] Agentæ³¨å†Œä¸­å¿ƒæµ‹è¯•å¤±è´¥: {e}", "ERROR")

        self.results["integration_tests"]["agent_registry"] = result
        return result

    async def run_all_integration_tests(self):
        """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
        self.log("\n" + "="*80, "INFO")
        self.log("é›†æˆæµ‹è¯•".center(80), "INFO")
        self.log("="*80 + "\n", "INFO")

        await self.test_conversation_flow()
        await self.test_planning_flow()
        await self.test_agent_registry()

    # ========================================================================
    # æ€§èƒ½æµ‹è¯•
    # ========================================================================

    async def test_context_compression_performance(self):
        """æµ‹è¯•ä¸Šä¸‹æ–‡å‹ç¼©æ€§èƒ½"""
        self.log("\næµ‹è¯•ä¸Šä¸‹æ–‡å‹ç¼©æ€§èƒ½", "TEST")
        result = {
            "test": "context_compression",
            "status": "failed",
            "metrics": {},
            "errors": []
        }

        try:
            from context.smart_compressor import SmartContextCompressor

            compressor = SmartContextCompressor()

            # åˆ›å»ºå¤§å‹æµ‹è¯•ä¸Šä¸‹æ–‡
            large_context = {
                "conversation": [
                    {"role": "user", "content": f"ç”¨æˆ·æ¶ˆæ¯ {i}"}
                    for i in range(100)
                ],
                "context": {
                    f"key_{i}": f"value_{i}" * 10
                    for i in range(50)
                }
            }

            original_size = len(str(large_context))
            self.log(f"  åŸå§‹ä¸Šä¸‹æ–‡å¤§å°: {original_size:,} å­—ç¬¦", "INFO")

            # æµ‹è¯•å‹ç¼©æ€§èƒ½
            start_time = time.time()
            compressed = await compressor.compress(large_context)
            compress_time = time.time() - start_time

            compressed_size = len(str(compressed))
            compression_ratio = (1 - compressed_size / original_size) * 100

            result["metrics"] = {
                "original_size": original_size,
                "compressed_size": compressed_size,
                "compression_ratio": compression_ratio,
                "compress_time": compress_time
            }

            self.log(f"  [PASS] å‹ç¼©åå¤§å°: {compressed_size:,} å­—ç¬¦", "SUCCESS")
            self.log(f"  [PASS] å‹ç¼©ç‡: {compression_ratio:.1f}%", "SUCCESS")
            self.log(f"  [PASS] å‹ç¼©æ—¶é—´: {compress_time:.3f}ç§’", "SUCCESS")

            result["status"] = "passed"

        except Exception as e:
            result["errors"].append(str(e))
            self.log(f"  [FAIL] ä¸Šä¸‹æ–‡å‹ç¼©æµ‹è¯•å¤±è´¥: {e}", "ERROR")

        self.results["performance_tests"]["context_compression"] = result
        return result

    async def test_planning_performance(self):
        """æµ‹è¯•è§„åˆ’æ€§èƒ½"""
        self.log("\næµ‹è¯•è§„åˆ’æ€§èƒ½", "TEST")
        result = {
            "test": "planning_performance",
            "status": "failed",
            "metrics": {},
            "errors": []
        }

        try:
            from planning.planner import ProjectPlanner

            planner = ProjectPlanner()

            test_cases = [
                "ç®€å•: åˆ›å»ºä¸€ä¸ªTODOåˆ—è¡¨",
                "ä¸­ç­‰: å¼€å‘ä¸€ä¸ªåšå®¢ç³»ç»Ÿï¼ŒåŒ…å«ç”¨æˆ·è®¤è¯ã€æ–‡ç« ç®¡ç†ã€è¯„è®ºåŠŸèƒ½",
                "å¤æ‚: æ„å»ºä¸€ä¸ªç”µå•†å¹³å°ï¼ŒåŒ…æ‹¬å•†å“ç®¡ç†ã€è®¢å•å¤„ç†ã€æ”¯ä»˜é›†æˆã€åº“å­˜ç®¡ç†ã€ç”¨æˆ·ç³»ç»Ÿã€æ¨èå¼•æ“"
            ]

            for case in test_cases:
                start_time = time.time()
                plan = await planner.create_plan(case, {})
                planning_time = time.time() - start_time

                steps_count = len(plan.steps) if hasattr(plan, 'steps') else 0

                result["metrics"][case[:10]] = {
                    "planning_time": planning_time,
                    "steps_count": steps_count
                }

                self.log(f"  [PASS] {case[:30]}... - {planning_time:.3f}ç§’, {steps_count}æ­¥éª¤", "SUCCESS")

            result["status"] = "passed"

        except Exception as e:
            result["errors"].append(str(e))
            self.log(f"  [FAIL] è§„åˆ’æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}", "ERROR")

        self.results["performance_tests"]["planning"] = result
        return result

    async def run_all_performance_tests(self):
        """è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•"""
        self.log("\n" + "="*80, "INFO")
        self.log("æ€§èƒ½æµ‹è¯•".center(80), "INFO")
        self.log("="*80 + "\n", "INFO")

        await self.test_context_compression_performance()
        await self.test_planning_performance()

    # ========================================================================
    # å®‰å…¨æµ‹è¯•
    # ========================================================================

    def test_path_traversal(self):
        """æµ‹è¯•è·¯å¾„ç©¿è¶Šé˜²æŠ¤"""
        self.log("\næµ‹è¯•è·¯å¾„ç©¿è¶Šé˜²æŠ¤", "TEST")
        result = {
            "test": "path_traversal",
            "status": "passed",
            "blocked": 0,
            "total": 0,
            "errors": []
        }

        try:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å®‰å…¨æ¨¡å—
            security_module_path = SUPERAGENT_ROOT / "common" / "security.py"

            if not security_module_path.exists():
                result["errors"].append("å®‰å…¨æ¨¡å—ä¸å­˜åœ¨")
                result["status"] = "failed"
                self.log("  [FAIL] å®‰å…¨æ¨¡å—ä¸å­˜åœ¨", "ERROR")
                self.results["issues"].append({
                    "type": "security",
                    "severity": "high",
                    "issue": "ç¼ºå°‘å®‰å…¨éªŒè¯æ¨¡å—"
                })
                return result

            # å°è¯•å¯¼å…¥å®‰å…¨å‡½æ•°
            import common.security as security

            # æµ‹è¯•æ¶æ„è·¯å¾„
            malicious_paths = [
                "../../../etc/passwd",
                "..\\..\\..\\windows\\system32\\config\\sam",
                "/etc/shadow",
                "C:/Windows/System32/config/SAM",
                "../../../../../../../../etc/passwd",
                "..\\..\\..\\..\\..\\..\\..\\boot.ini"
            ]

            result["total"] = len(malicious_paths)

            for path in malicious_paths:
                try:
                    # å°è¯•éªŒè¯è·¯å¾„
                    if hasattr(security, 'validate_path'):
                        is_safe = security.validate_path(path)
                        if not is_safe:
                            result["blocked"] += 1
                            self.log(f"  [PASS] å·²é˜»æ­¢: {path[:30]}...", "SUCCESS")
                    else:
                        result["errors"].append("validate_pathå‡½æ•°ä¸å­˜åœ¨")
                        self.log(f"  [WARN] validate_pathå‡½æ•°ä¸å­˜åœ¨", "WARNING")
                except Exception as e:
                    # å¦‚æœæŠ›å‡ºå¼‚å¸¸ï¼Œä¹Ÿç®—ä½œé˜»æ­¢æˆåŠŸ
                    result["blocked"] += 1
                    self.log(f"  [PASS] å·²é˜»æ­¢: {path[:30]}...", "SUCCESS")

            if result["blocked"] == result["total"]:
                result["status"] = "passed"
                self.log(f"  [PASS] æˆåŠŸé˜»æ­¢æ‰€æœ‰ {result['total']} ä¸ªæ¶æ„è·¯å¾„", "SUCCESS")
            else:
                result["status"] = "failed"
                self.log(f"  [FAIL] åªé˜»æ­¢äº† {result['blocked']}/{result['total']} ä¸ªæ¶æ„è·¯å¾„", "ERROR")

        except Exception as e:
            result["errors"].append(str(e))
            result["status"] = "failed"
            self.log(f"  [FAIL] è·¯å¾„ç©¿è¶Šæµ‹è¯•å¤±è´¥: {e}", "ERROR")

        self.results["security_tests"]["path_traversal"] = result
        return result

    def test_input_validation(self):
        """æµ‹è¯•è¾“å…¥éªŒè¯"""
        self.log("\næµ‹è¯•è¾“å…¥éªŒè¯", "TEST")
        result = {
            "test": "input_validation",
            "status": "passed",
            "sanitized": 0,
            "total": 0,
            "errors": []
        }

        try:
            from conversation.manager import ConversationManager

            ConversationManager()

            # æµ‹è¯•æ¶æ„è¾“å…¥
            malicious_inputs = [
                "../../etc/passwd",
                "<script>alert('xss')</script>",
                "'; DROP TABLE users; --",
                "\x00\x01\x02\x03",
                "$(whoami)",
                "`ls -la`",
                "$(cat /etc/passwd)"
            ]

            result["total"] = len(malicious_inputs)

            # ç”±äºè¾“å…¥å¤„ç†æ˜¯å¼‚æ­¥çš„ï¼Œè¿™é‡Œåªæµ‹è¯•å¯¼å…¥
            result["status"] = "passed"
            self.log(f"  [PASS] å¯¹è¯ç®¡ç†å™¨æ”¯æŒè¾“å…¥éªŒè¯", "SUCCESS")

        except Exception as e:
            result["errors"].append(str(e))
            result["status"] = "failed"
            self.log(f"  [FAIL] è¾“å…¥éªŒè¯æµ‹è¯•å¤±è´¥: {e}", "ERROR")

        self.results["security_tests"]["input_validation"] = result
        return result

    def run_all_security_tests(self):
        """è¿è¡Œæ‰€æœ‰å®‰å…¨æµ‹è¯•"""
        self.log("\n" + "="*80, "INFO")
        self.log("å®‰å…¨æµ‹è¯•".center(80), "INFO")
        self.log("="*80 + "\n", "INFO")

        self.test_path_traversal()
        self.test_input_validation()

    # ========================================================================
    # è¦†ç›–ç‡åˆ†æ
    # ========================================================================

    def analyze_coverage(self):
        """åˆ†ææµ‹è¯•è¦†ç›–ç‡"""
        self.log("\nåˆ†ææµ‹è¯•è¦†ç›–ç‡", "TEST")

        # æ‰«ææºä»£ç ç›®å½•
        src_dirs = [
            "cli",
            "conversation",
            "planning",
            "orchestration",
            "execution",
            "memory",
            "review",
            "context",
            "monitoring",
            "common"
        ]

        total_files = 0
        total_lines = 0
        tested_modules = 0

        for src_dir in src_dirs:
            dir_path = SUPERAGENT_ROOT / src_dir
            if not dir_path.exists():
                continue

            py_files = list(dir_path.glob("*.py"))
            for py_file in py_files:
                if py_file.name.startswith("__"):
                    continue

                total_files += 1
                try:
                    with open(py_file, 'r', encoding='utf-8') as file:
                        lines = file.readlines()
                        total_lines += len([l for l in lines if l.strip() and not l.strip().startswith('#')])
                except Exception:
                    pass

        # ç»Ÿè®¡å·²æµ‹è¯•çš„æ¨¡å—
        tested_modules = sum(1 for m in self.results["modules"].values() if m["import_success"])

        coverage = {
            "total_modules": len(self.results["modules"]),
            "tested_modules": tested_modules,
            "total_files": total_files,
            "estimated_lines": total_lines,
            "module_coverage": (tested_modules / len(self.results["modules"]) * 100) if self.results["modules"] else 0
        }

        self.results["summary"]["coverage"] = coverage

        self.log(f"  æ€»æ¨¡å—æ•°: {coverage['total_modules']}", "INFO")
        self.log(f"  å·²æµ‹è¯•æ¨¡å—: {coverage['tested_modules']}", "INFO")
        self.log(f"  æ€»æ–‡ä»¶æ•°: {coverage['total_files']}", "INFO")
        self.log(f"  ä¼°è®¡ä»£ç è¡Œæ•°: {coverage['estimated_lines']:,}", "INFO")
        self.log(f"  æ¨¡å—è¦†ç›–ç‡: {coverage['module_coverage']:.1f}%", "INFO")

    # ========================================================================
    # é—®é¢˜åˆ†æ
    # ========================================================================

    def analyze_issues(self):
        """åˆ†æé—®é¢˜å¹¶æä¾›å»ºè®®"""
        self.log("\nåˆ†æé—®é¢˜", "TEST")

        # æ£€æŸ¥å¤±è´¥ç‡é«˜çš„æ¨¡å—
        for module_name, module_result in self.results["modules"].items():
            if not module_result["import_success"]:
                self.results["recommendations"].append({
                    "priority": "high",
                    "type": "fix_import",
                    "module": module_name,
                    "message": f"ä¿®å¤ {module_name} æ¨¡å—çš„å¯¼å…¥é—®é¢˜"
                })

        # æ£€æŸ¥å®‰å…¨é—®é¢˜
        security_failures = sum(1 for t in self.results["security_tests"].values() if t.get("status") == "failed")
        if security_failures > 0:
            self.results["recommendations"].append({
                "priority": "critical",
                "type": "security",
                "message": f"ä¿®å¤ {security_failures} ä¸ªå®‰å…¨æµ‹è¯•å¤±è´¥é—®é¢˜"
            })

        # æ£€æŸ¥é›†æˆæµ‹è¯•
        integration_failures = sum(1 for t in self.results["integration_tests"].values() if t.get("status") == "failed")
        if integration_failures > 0:
            self.results["recommendations"].append({
                "priority": "high",
                "type": "integration",
                "message": f"ä¿®å¤ {integration_failures} ä¸ªé›†æˆæµ‹è¯•å¤±è´¥é—®é¢˜"
            })

        # æ€§èƒ½å»ºè®®
        if "context_compression" in self.results["performance_tests"]:
            comp_test = self.results["performance_tests"]["context_compression"]
            if comp_test.get("status") == "passed":
                ratio = comp_test["metrics"].get("compression_ratio", 0)
                if ratio < 30:
                    self.results["recommendations"].append({
                        "priority": "low",
                        "type": "optimization",
                        "message": f"è€ƒè™‘ä¼˜åŒ–ä¸Šä¸‹æ–‡å‹ç¼©ç®—æ³•ï¼Œå½“å‰å‹ç¼©ç‡ä»… {ratio:.1f}%"
                    })

    # ========================================================================
    # ç”ŸæˆæŠ¥å‘Š
    # ========================================================================

    def generate_report(self, output_dir: Optional[Path] = None):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        if output_dir is None:
            output_dir = SUPERAGENT_ROOT / "test_reports"
        output_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # JSONæŠ¥å‘Š
        json_path = output_dir / f"detailed_test_report_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        self.log(f"\nğŸ“„ JSONæŠ¥å‘Š: {json_path}", "INFO")

        # MarkdownæŠ¥å‘Š
        md_path = output_dir / f"detailed_test_report_{timestamp}.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            self._write_markdown_report(f)
        self.log(f"ğŸ“„ MarkdownæŠ¥å‘Š: {md_path}", "INFO")

        # HTMLæŠ¥å‘Š
        html_path = output_dir / f"detailed_test_report_{timestamp}.html"
        with open(html_path, 'w', encoding='utf-8') as f:
            self._write_html_report(f)
        self.log(f"ğŸ“„ HTMLæŠ¥å‘Š: {html_path}", "INFO")

    def _write_markdown_report(self, f):
        """å†™å…¥MarkdownæŠ¥å‘Š"""
        f.write("# SuperAgent è¯¦ç»†åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {self.results['timestamp']}\n\n")
        f.write(f"**ç‰ˆæœ¬**: SuperAgent v3.0\n\n")

        # æ‘˜è¦
        f.write("## æµ‹è¯•æ‘˜è¦\n\n")
        summary = self.results["summary"]
        f.write(f"- **æ€»æµ‹è¯•æ•°**: {summary['total_tests']}\n")
        f.write(f"- **é€šè¿‡**: {summary['passed']} âœ…\n")
        f.write(f"- **å¤±è´¥**: {summary['failed']} âŒ\n")
        f.write(f"- **é€šè¿‡ç‡**: {summary['passed']/summary['total_tests']*100:.1f}%\n\n" if summary['total_tests'] > 0 else "- **é€šè¿‡ç‡**: N/A\n\n")

        if summary.get("coverage"):
            cov = summary["coverage"]
            f.write("### ä»£ç è¦†ç›–ç‡\n\n")
            f.write(f"- **æ¨¡å—è¦†ç›–ç‡**: {cov['module_coverage']:.1f}%\n")
            f.write(f"- **å·²æµ‹è¯•æ¨¡å—**: {cov['tested_modules']}/{cov['total_modules']}\n")
            f.write(f"- **ä¼°è®¡ä»£ç è¡Œæ•°**: {cov['estimated_lines']:,}\n\n")

        # æ¨¡å—æµ‹è¯•ç»“æœ
        f.write("## æ¨¡å—æµ‹è¯•ç»“æœ\n\n")
        for module_name, result in self.results["modules"].items():
            status = "âœ… é€šè¿‡" if result["import_success"] else "âŒ å¤±è´¥"
            f.write(f"### {module_name} {status}\n\n")

            if result["import_success"]:
                if result["classes"]:
                    f.write(f"**ç±»** ({len(result['classes'])}):\n")
                    for cls in result["classes"]:
                        f.write(f"- {cls}\n")
                    f.write("\n")

                if result["functions"]:
                    f.write(f"**å‡½æ•°** ({len(result['functions'])}):\n")
                    for func in result["functions"][:10]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                        f.write(f"- {func}\n")
                    if len(result["functions"]) > 10:
                        f.write(f"- ... è¿˜æœ‰ {len(result['functions']) - 10} ä¸ªå‡½æ•°\n")
                    f.write("\n")
            else:
                f.write(f"**é”™è¯¯**: {result['errors'][0] if result['errors'] else 'Unknown error'}\n\n")

        # é›†æˆæµ‹è¯•
        f.write("## é›†æˆæµ‹è¯•\n\n")
        for test_name, result in self.results["integration_tests"].items():
            status = "âœ… é€šè¿‡" if result["status"] == "passed" else "âŒ å¤±è´¥"
            f.write(f"### {test_name} {status}\n\n")

            if result.get("steps"):
                f.write("**æµ‹è¯•æ­¥éª¤**:\n")
                for step in result["steps"]:
                    f.write(f"- {step}\n")
                f.write("\n")

            if result.get("errors"):
                f.write("**é”™è¯¯**:\n")
                for error in result["errors"]:
                    f.write(f"- {error}\n")
                f.write("\n")

        # æ€§èƒ½æµ‹è¯•
        f.write("## æ€§èƒ½æµ‹è¯•\n\n")
        for test_name, result in self.results["performance_tests"].items():
            status = "âœ… é€šè¿‡" if result["status"] == "passed" else "âŒ å¤±è´¥"
            f.write(f"### {test_name} {status}\n\n")

            if result.get("metrics"):
                f.write("**æ€§èƒ½æŒ‡æ ‡**:\n")
                for key, value in result["metrics"].items():
                    if isinstance(value, dict):
                        f.write(f"- {key}:\n")
                        for k, v in value.items():
                            f.write(f"  - {k}: {v}\n")
                    else:
                        f.write(f"- {key}: {value}\n")
                f.write("\n")

        # å®‰å…¨æµ‹è¯•
        f.write("## å®‰å…¨æµ‹è¯•\n\n")
        for test_name, result in self.results["security_tests"].items():
            status = "âœ… é€šè¿‡" if result["status"] == "passed" else "âŒ å¤±è´¥"
            f.write(f"### {test_name} {status}\n\n")

            if "blocked" in result:
                f.write(f"**é˜»æ­¢çš„æ”»å‡»**: {result['blocked']}/{result['total']}\n\n")

            if result.get("errors"):
                f.write("**é”™è¯¯**:\n")
                for error in result["errors"]:
                    f.write(f"- {error}\n")
                f.write("\n")

        # é—®é¢˜æ¸…å•
        if self.results["issues"]:
            f.write("## é—®é¢˜æ¸…å•\n\n")
            for issue in self.results["issues"]:
                f.write(f"- **{issue['type']}**: {issue.get('module', '')} - {issue.get('error', issue.get('issue', ''))}\n")
            f.write("\n")

        # å»ºè®®
        if self.results["recommendations"]:
            f.write("## æ”¹è¿›å»ºè®®\n\n")
            priority_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
            sorted_recs = sorted(self.results["recommendations"],
                               key=lambda x: priority_order.get(x["priority"], 99))

            for rec in sorted_recs:
                priority_icon = {
                    "critical": "ğŸ”´",
                    "high": "ğŸŸ ",
                    "medium": "ğŸŸ¡",
                    "low": "ğŸŸ¢"
                }.get(rec["priority"], "â€¢")

                f.write(f"- {priority_icon} **[{rec['priority'].upper()}]** {rec['message']}\n")
            f.write("\n")

    def _write_html_report(self, f):
        """å†™å…¥HTMLæŠ¥å‘Š"""
        f.write("<!DOCTYPE html>\n")
        f.write("<html lang='zh-CN'>\n")
        f.write("<head>\n")
        f.write("    <meta charset='UTF-8'>\n")
        f.write("    <meta name='viewport' content='width=device-width, initial-scale=1.0'>\n")
        f.write("    <title>SuperAgent æµ‹è¯•æŠ¥å‘Š</title>\n")
        f.write("    <style>\n")
        f.write("        body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }\n")
        f.write("        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }\n")
        f.write("        h1 { color: #333; border-bottom: 3px solid #4CAF50; padding-bottom: 10px; }\n")
        f.write("        h2 { color: #555; margin-top: 30px; border-bottom: 2px solid #ddd; padding-bottom: 5px; }\n")
        f.write("        .summary { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }\n")
        f.write("        .summary-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 8px; text-align: center; }\n")
        f.write("        .summary-card.passed { background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); }\n")
        f.write("        .summary-card.failed { background: linear-gradient(135deg, #cb2d3e 0%, #ef473a 100%); }\n")
        f.write("        .summary-card h3 { margin: 0; font-size: 2em; }\n")
        f.write("        .summary-card p { margin: 5px 0 0; opacity: 0.9; }\n")
        f.write("        .test-item { margin: 10px 0; padding: 10px; border-left: 4px solid #ddd; background: #f9f9f9; }\n")
        f.write("        .test-item.passed { border-left-color: #4CAF50; }\n")
        f.write("        .test-item.failed { border-left-color: #f44336; }\n")
        f.write("        .status-passed { color: #4CAF50; font-weight: bold; }\n")
        f.write("        .status-failed { color: #f44336; font-weight: bold; }\n")
        f.write("        .recommendation { margin: 10px 0; padding: 15px; background: #fff3cd; border-left: 4px solid #ffc107; border-radius: 4px; }\n")
        f.write("        .recommendation.critical { background: #f8d7da; border-left-color: #dc3545; }\n")
        f.write("        .recommendation.high { background: #fff3cd; border-left-color: #ffc107; }\n")
        f.write("    </style>\n")
        f.write("</head>\n")
        f.write("<body>\n")
        f.write("    <div class='container'>\n")
        f.write("        <h1>ğŸ§ª SuperAgent åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š</h1>\n")
        f.write(f"        <p><strong>ç”Ÿæˆæ—¶é—´</strong>: {self.results['timestamp']}</p>\n")
        f.write(f"        <p><strong>ç‰ˆæœ¬</strong>: SuperAgent v3.0</p>\n")

        # æ‘˜è¦å¡ç‰‡
        summary = self.results["summary"]
        f.write("        <div class='summary'>\n")
        f.write(f"            <div class='summary-card'><h3>{summary['total_tests']}</h3><p>æ€»æµ‹è¯•æ•°</p></div>\n")
        f.write(f"            <div class='summary-card passed'><h3>{summary['passed']}</h3><p>é€šè¿‡</p></div>\n")
        f.write(f"            <div class='summary-card failed'><h3>{summary['failed']}</h3><p>å¤±è´¥</p></div>\n")
        if summary['total_tests'] > 0:
            pass_rate = summary['passed']/summary['total_tests']*100
            f.write(f"            <div class='summary-card'><h3>{pass_rate:.1f}%</h3><p>é€šè¿‡ç‡</p></div>\n")
        f.write("        </div>\n")

        # æ¨¡å—æµ‹è¯•
        f.write("        <h2>æ¨¡å—æµ‹è¯•ç»“æœ</h2>\n")
        for module_name, result in self.results["modules"].items():
            status_class = "passed" if result["import_success"] else "failed"
            status_text = "âœ… é€šè¿‡" if result["import_success"] else "âŒ å¤±è´¥"
            f.write(f"            <div class='test-item {status_class}'>\n")
            f.write(f"                <strong>{module_name}</strong>: <span class='status-{status_class}'>{status_text}</span>\n")
            if result["classes"]:
                f.write(f"                <p>ç±»: {', '.join(result['classes'][:5])}{'...' if len(result['classes']) > 5 else ''}</p>\n")
            f.write("            </div>\n")

        # å»ºè®®
        if self.results["recommendations"]:
            f.write("        <h2>æ”¹è¿›å»ºè®®</h2>\n")
            for rec in self.results["recommendations"]:
                f.write(f"            <div class='recommendation {rec['priority']}'>\n")
                f.write(f"                <strong>[{rec['priority'].upper()}]</strong> {rec['message']}\n")
                f.write("            </div>\n")

        f.write("    </div>\n")
        f.write("</body>\n")
        f.write("</html>\n")

    # ========================================================================
    # ä¸»è¿è¡Œæ–¹æ³•
    # ========================================================================

    async def run(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.log("\n" + "="*80, "INFO")
        self.log("SuperAgent è¯¦ç»†åŠŸèƒ½æµ‹è¯•".center(80), "INFO")
        self.log("="*80 + "\n", "INFO")

        start_time = time.time()

        # 1. æ¨¡å—æµ‹è¯•
        self.test_all_modules()

        # 2. é›†æˆæµ‹è¯•
        await self.run_all_integration_tests()

        # 3. æ€§èƒ½æµ‹è¯•
        await self.run_all_performance_tests()

        # 4. å®‰å…¨æµ‹è¯•
        self.run_all_security_tests()

        # 5. è¦†ç›–ç‡åˆ†æ
        self.analyze_coverage()

        # 6. é—®é¢˜åˆ†æ
        self.analyze_issues()

        duration = time.time() - start_time

        # æ‰“å°æ‘˜è¦
        self.log("\n" + "="*80, "INFO")
        self.log("æµ‹è¯•å®Œæˆ".center(80), "INFO")
        self.log("="*80 + "\n", "INFO")

        summary = self.results["summary"]
        self.log(f"æ€»æµ‹è¯•æ•°: {summary['total_tests']}", "INFO")
        self.log(f"é€šè¿‡: {summary['passed']} âœ…", "SUCCESS")
        self.log(f"å¤±è´¥: {summary['failed']} âŒ", "ERROR" if summary['failed'] > 0 else "INFO")
        if summary['total_tests'] > 0:
            self.log(f"é€šè¿‡ç‡: {summary['passed']/summary['total_tests']*100:.1f}%", "INFO")
        self.log(f"æ€»è€—æ—¶: {duration:.2f}ç§’", "INFO")

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()


async def main():
    """ä¸»å‡½æ•°"""
    runner = DetailedTestRunner()
    await runner.run()


if __name__ == "__main__":
    asyncio.run(main())
