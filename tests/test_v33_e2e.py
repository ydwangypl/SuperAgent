#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
SuperAgent v3.3 ç«¯åˆ°ç«¯æµ‹è¯•

æµ‹è¯•å†…å®¹ï¼š
1. MemoryManager å•ä¾‹å’Œç¼“å­˜åŠŸèƒ½
2. TaskListManager JSON â†’ MD åŒæ­¥
3. BaseAgent findings/progress åŠŸèƒ½
4. Orchestrator æ‰©å±•æ¨¡å—é›†æˆ
5. Hook ç³»ç»ŸåŠŸèƒ½
"""

import asyncio
import sys
import tempfile
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

print("=" * 60)
print("SuperAgent v3.3 ç«¯åˆ°ç«¯æµ‹è¯•")
print("=" * 60)


async def test_memory_manager():
    """æµ‹è¯• MemoryManager çš„ v3.3 æ”¹è¿›"""
    print("\n[TEST 1] MemoryManager å•ä¾‹å’Œç¼“å­˜åŠŸèƒ½")
    print("-" * 40)

    from memory.memory_manager import MemoryManager

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as tmpdir:
        project_root = Path(tmpdir)

        # æµ‹è¯•å•ä¾‹æ¨¡å¼
        print("  âœ“ æµ‹è¯•å•ä¾‹æ¨¡å¼...")
        mm1 = MemoryManager(project_root)
        mm2 = MemoryManager(project_root)
        assert mm1 is mm2, "å•ä¾‹æ¨¡å¼å¤±è´¥"
        print("    å•ä¾‹æ¨¡å¼: PASS")

        # æµ‹è¯•ç¼“å­˜æ“ä½œ
        print("  âœ“ æµ‹è¯•ç¼“å­˜æ“ä½œ...")
        test_entry = {"content": "æµ‹è¯•è®°å¿†", "type": "test"}
        mm1._save_to_cache("episodic", "test_id", test_entry)
        cached = mm1._get_from_cache("episodic", "test_id")
        assert cached is not None, "ç¼“å­˜å†™å…¥å¤±è´¥"
        assert cached["content"] == "æµ‹è¯•è®°å¿†", "ç¼“å­˜è¯»å–å¤±è´¥"
        print("    ç¼“å­˜æ“ä½œ: PASS")

        # æµ‹è¯•ç¼“å­˜æ·˜æ±°ç­–ç•¥
        print("  âœ“ æµ‹è¯•ç¼“å­˜æ·˜æ±°ç­–ç•¥...")
        for i in range(1005):  # è¶…è¿‡ max_cache_size (1000)
            mm1._save_to_cache("semantic", f"test_{i}", {"id": i})
        assert len(mm1._cache["semantic"]) <= 1001, "ç¼“å­˜æ·˜æ±°å¤±è´¥"
        print("    ç¼“å­˜æ·˜æ±°: PASS")

        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        print("  âœ“ æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯...")
        stats = mm1.get_statistics()
        assert "cache_hit_rate" in stats, "ç¼ºå°‘ cache_hit_rate"
        assert "index_ready" in stats, "ç¼ºå°‘ index_ready"
        print(f"    ç¼“å­˜å‘½ä¸­ç‡: {stats['cache_hit_rate']}%")
        print("    ç»Ÿè®¡ä¿¡æ¯: PASS")

    print("\n[TEST 1] MemoryManager: ALL PASS âœ“")


async def test_task_list_manager():
    """æµ‹è¯• TaskListManager çš„ JSON â†’ MD åŒæ­¥"""
    print("\n[TEST 2] TaskListManager JSON â†’ MD åŒæ­¥")
    print("-" * 40)

    from core.task_list_manager import TaskListManager, TaskItem, TaskList

    with tempfile.TemporaryDirectory() as tmpdir:
        project_root = Path(tmpdir)

        # åˆ›å»º TaskListManager
        print("  âœ“ åˆ›å»º TaskListManager...")
        manager = TaskListManager(project_root, enable_markdown_sync=True)
        assert manager._task_plan_manager is not None, "TaskPlanManager æœªåˆå§‹åŒ–"
        print("    TaskListManager: PASS")

        # åˆ›å»ºæ¨¡æ‹Ÿè®¡åˆ’
        class MockStep:
            def __init__(self, id, description, agent_type):
                self.id = id
                self.description = description
                self.agent_type = agent_type
                self.test_steps = []
                self.dependencies = []

        class MockPlan:
            def __init__(self):
                self.steps = [
                    MockStep("task-001", "ç¬¬ä¸€æ­¥ä»»åŠ¡", "CodingAgent"),
                    MockStep("task-002", "ç¬¬äºŒæ­¥ä»»åŠ¡", "CodingAgent"),
                ]
                self.requirements = type('obj', (object,), {'user_input': 'æµ‹è¯•é¡¹ç›®'})()

        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        print("  âœ“ æµ‹è¯• create_from_plan...")
        manager.create_from_plan(MockPlan())

        # ç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ
        await asyncio.sleep(0.5)

        # æ£€æŸ¥ task_plan.md æ˜¯å¦åˆ›å»º
        task_plan_file = project_root / "task_plan.md"
        assert task_plan_file.exists(), f"task_plan.md æœªåˆ›å»º, å®é™…è·¯å¾„: {task_plan_file}"
        print("    task_plan.md åˆ›å»º: PASS")

        # è¯»å–å†…å®¹éªŒè¯æ ¼å¼
        content = task_plan_file.read_text(encoding='utf-8')
        assert "task-001" in content, "task-001 æœªæ‰¾åˆ°"
        assert "task-002" in content, "task-002 æœªæ‰¾åˆ°"
        assert "[ ]" in content, "checkbox æœªåˆ›å»º"
        print("    task_plan.md æ ¼å¼: PASS")

        # æµ‹è¯•å¼‚æ­¥ç‰ˆæœ¬
        print("  âœ“ æµ‹è¯• create_from_plan_async...")
        manager2 = TaskListManager(project_root, enable_markdown_sync=True)
        result = await manager2.create_from_plan_async(MockPlan())
        assert result is not None, "å¼‚æ­¥ç‰ˆæœ¬å¤±è´¥"
        print("    å¼‚æ­¥ç‰ˆæœ¬: PASS")

    print("\n[TEST 2] TaskListManager: ALL PASS âœ“")


async def test_planning_files():
    """æµ‹è¯• Planning Files æ¨¡å—"""
    print("\n[TEST 3] Planning Files æ¨¡å—")
    print("-" * 40)

    from extensions.planning_files import (
        TaskPlanManager, FindingsManager, ProgressManager, CompletionChecker
    )

    with tempfile.TemporaryDirectory() as tmpdir:
        project_root = Path(tmpdir)

        # æµ‹è¯• TaskPlanManager
        print("  âœ“ æµ‹è¯• TaskPlanManager...")
        task_plan = project_root / "test_plan.md"
        tpm = TaskPlanManager(project_root, task_plan, auto_save=True)

        requirements = {
            "user_input": "æµ‹è¯•é¡¹ç›®",
            "analysis": {"complexity": "low", "tech_stack": "Python"}
        }
        steps = [
            {"step_id": "step-1", "name": "Step 1", "description": "ç¬¬ä¸€æ­¥", "agent_type": "Agent"},
        ]
        dependencies = {}

        await tpm.create_plan(requirements, steps, dependencies)
        assert task_plan.exists(), "task_plan.md æœªåˆ›å»º"
        print("    TaskPlanManager: PASS")

        # æµ‹è¯•æ›´æ–° checkbox
        print("  âœ“ æµ‹è¯•æ›´æ–° checkbox...")
        result = await tpm.update_task_status("step-1", "completed")
        assert result, "æ›´æ–° checkbox å¤±è´¥"

        content = task_plan.read_text(encoding='utf-8')
        assert "[x]" in content, "checkbox æœªæ›´æ–°ä¸ºå·²å®Œæˆ"
        print("    Checkbox æ›´æ–°: PASS")

        # æµ‹è¯• FindingsManager
        print("  âœ“ æµ‹è¯• FindingsManager...")
        fm = FindingsManager(
            project_root=project_root,
            findings_file=project_root / "docs" / "findings.md"
        )
        finding_id = await fm.add_finding(
            content="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å‘ç°",
            category="test",
            impact="ä½",
            source="unit_test"
        )
        assert finding_id is not None, "æ·»åŠ å‘ç°å¤±è´¥"
        print("    FindingsManager: PASS")

        # æµ‹è¯• ProgressManager
        print("  âœ“ æµ‹è¯• ProgressManager...")
        pm = ProgressManager(
            project_root=project_root,
            progress_file=project_root / "docs" / "progress.md",
            session_id="test-session"
        )
        await pm.log_progress(action="æµ‹è¯•åŠ¨ä½œ", status="started", details="æµ‹è¯•è¯¦æƒ…")
        await pm.log_progress(action="æµ‹è¯•åŠ¨ä½œ", status="completed", details="å®Œæˆ")
        print("    ProgressManager: PASS")

        # æµ‹è¯• CompletionChecker
        print("  âœ“ æµ‹è¯• CompletionChecker...")
        cc = CompletionChecker(tpm)
        report = await cc.check_all()
        assert report is not None, "å®Œæˆåº¦æ£€æŸ¥å¤±è´¥"
        print("    CompletionChecker: PASS")

    print("\n[TEST 3] Planning Files: ALL PASS âœ“")


async def test_hooks():
    """æµ‹è¯• Hook ç³»ç»Ÿ"""
    print("\n[TEST 4] Hook ç³»ç»Ÿ")
    print("-" * 40)

    from extensions.hooks import (
        HookManager, HookContext, HookResult, LifecycleHookType,
        ReReadPlanHook, UpdateStatusHook, LogProgressHook
    )

    # æµ‹è¯• HookManager
    print("  âœ“ æµ‹è¯• HookManager...")
    manager = HookManager(memory_manager=None)

    # åˆ›å»ºæ¨¡æ‹Ÿçš„ managers
    class MockTaskPlanManager:
        async def read_plan(self):
            return "# æµ‹è¯•è®¡åˆ’\n- Task step-1: ç¬¬ä¸€æ­¥"

    class MockProgressManager:
        async def log_progress(self, **kwargs):
            pass

        async def log_session_summary(self, task_count: int, status: str, errors = None):
            pass

    mock_tpm = MockTaskPlanManager()
    mock_pm = MockProgressManager()

    # æ³¨å†Œé’©å­
    hook1 = ReReadPlanHook(task_plan_manager=mock_tpm)
    hook2 = UpdateStatusHook(task_plan_manager=mock_tpm, progress_manager=mock_pm)
    hook3 = LogProgressHook(progress_manager=mock_pm)

    manager.register(hook1)
    manager.register(hook2)
    manager.register(hook3)

    # ç»Ÿè®¡æ‰€æœ‰å·²æ³¨å†Œçš„é’©å­æ•°é‡
    total_hooks = sum(len(hooks) for hooks in manager._registrations.values())
    assert total_hooks == 3, f"é’©å­æ³¨å†Œå¤±è´¥ (æœŸæœ›3ä¸ª,å®é™…{total_hooks}ä¸ª)"
    print("    HookManager: PASS")

    # æµ‹è¯•æ‰§è¡Œ PreExecute
    print("  âœ“ æµ‹è¯• PreExecute é’©å­æ‰§è¡Œ...")
    result = await manager.execute_pre_execute({
        "project_id": "test-project",
        "total_tasks": 5
    })
    assert isinstance(result, HookContext), "PreExecute è¿”å›ç±»å‹é”™è¯¯"
    print("    PreExecute: PASS")

    # æµ‹è¯•æ‰§è¡Œ PostExecute
    print("  âœ“ æµ‹è¯• PostExecute é’©å­æ‰§è¡Œ...")
    result = await manager.execute_post_execute(
        session_state={"completed_tasks": 3},
        execution_history=[]
    )
    assert isinstance(result, HookContext), "PostExecute è¿”å›ç±»å‹é”™è¯¯"
    print("    PostExecute: PASS")

    # æµ‹è¯•æ‰§è¡Œ Stop
    print("  âœ“ æµ‹è¯• Stop é’©å­æ‰§è¡Œ...")
    result = await manager.execute_stop({
        "completed": 3,
        "failed": 1,
        "total": 5
    })
    assert isinstance(result, HookResult), "Stop è¿”å›ç±»å‹é”™è¯¯"
    assert result.should_continue is True, "Stop should_continue é”™è¯¯"
    print("    Stop: PASS")

    print("\n[TEST 4] Hook ç³»ç»Ÿ: ALL PASS âœ“")


async def test_state_persistence():
    """æµ‹è¯•çŠ¶æ€æŒä¹…åŒ–æ¨¡å—"""
    print("\n[TEST 5] çŠ¶æ€æŒä¹…åŒ–æ¨¡å—")
    print("-" * 40)

    from extensions.state_persistence import (
        StateSerializer, JSONSerializer, SessionManager, SessionStatus
    )

    with tempfile.TemporaryDirectory() as tmpdir:
        project_root = Path(tmpdir)

        # æµ‹è¯• SessionManager
        print("  âœ“ æµ‹è¯• SessionManager...")
        sm = SessionManager(project_root)

        # å¼€å§‹ä¼šè¯
        await sm.start_session(
            session_id="test-session-001",
            initial_state={"test": "data"}
        )
        assert sm._current_session_id is not None, "ä¼šè¯æœªå¼€å§‹"
        print("    ä¼šè¯å¼€å§‹: PASS")

        # åˆ›å»ºæ£€æŸ¥ç‚¹
        print("  âœ“ æµ‹è¯•æ£€æŸ¥ç‚¹åˆ›å»º...")
        checkpoint = await sm.create_checkpoint(
            task_status={"task-1": "completed"},
            memory_summary={"total": 10},
            context_summary="æµ‹è¯•æ£€æŸ¥ç‚¹"
        )
        assert checkpoint is not None, "æ£€æŸ¥ç‚¹åˆ›å»ºå¤±è´¥"
        print("    æ£€æŸ¥ç‚¹åˆ›å»º: PASS")

        # è·å–ä¼šè¯çŠ¶æ€
        print("  âœ“ æµ‹è¯•ä¼šè¯çŠ¶æ€æŸ¥è¯¢...")
        status = sm.current_session_id is not None
        assert status is True, "ä¼šè¯çŠ¶æ€é”™è¯¯"
        print("    ä¼šè¯çŠ¶æ€: PASS")

        # ç»“æŸä¼šè¯
        print("  âœ“ æµ‹è¯•ä¼šè¯ç»“æŸ...")
        await sm.end_session(
            status=SessionStatus.COMPLETED,
            final_state={"result": "success"}
        )
        status = sm.current_session_id is None
        assert status is True, "ä¼šè¯æœªæ­£ç¡®ç»“æŸ"
        print("    ä¼šè¯ç»“æŸ: PASS")

        # æµ‹è¯•æ¢å¤
        print("  âœ“ æµ‹è¯•ä¼šè¯æ¢å¤...")
        report = await sm.recover_session("test-session-001")
        assert report is not None, "ä¼šè¯æ¢å¤å¤±è´¥"
        print("    ä¼šè¯æ¢å¤: PASS")

    print("\n[TEST 5] çŠ¶æ€æŒä¹…åŒ–: ALL PASS âœ“")


async def test_base_agent_extensions():
    """æµ‹è¯• BaseAgent çš„ v3.3 æ‰©å±•åŠŸèƒ½"""
    print("\n[TEST 6] BaseAgent v3.3 æ‰©å±•åŠŸèƒ½")
    print("-" * 40)

    from execution.base_agent import BaseAgent

    # æ£€æŸ¥åŠ¨æ€å¯¼å…¥
    print("  âœ“ æµ‹è¯• FindingsManager åŠ¨æ€å¯¼å…¥...")
    from execution.base_agent import FINDINGS_AVAILABLE, PROGRESS_AVAILABLE
    print(f"    FindingsManager å¯ç”¨: {FINDINGS_AVAILABLE}")
    print(f"    ProgressManager å¯ç”¨: {PROGRESS_AVAILABLE}")

    # åˆ›å»ºæµ‹è¯• Agent
    class TestAgent(BaseAgent):
        @classmethod
        def get_capabilities(cls):
            return set()

        @property
        def name(self):
            return "TestAgent"

        async def execute_impl(self, context, task_input):
            return []

        async def plan(self, context, task_input):
            return []

    agent = TestAgent("test-agent")

    # æµ‹è¯• setup_findings_manager
    print("  âœ“ æµ‹è¯• setup_findings_manager...")
    with tempfile.TemporaryDirectory() as tmpdir:
        agent.setup_findings_manager(Path(tmpdir))
        # å³ä½¿ FindingsManager ä¸å¯ç”¨ï¼Œä¹Ÿä¸åº”æŠ¥é”™
        print("    setup_findings_manager: PASS")

        # æµ‹è¯• setup_progress_manager
        print("  âœ“ æµ‹è¯• setup_progress_manager...")
        agent.setup_progress_manager(Path(tmpdir), session_id="test-session")
        print("    setup_progress_manager: PASS")

    print("\n[TEST 6] BaseAgent æ‰©å±•: ALL PASS âœ“")


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("å¼€å§‹æ‰§è¡Œ v3.3 ç«¯åˆ°ç«¯æµ‹è¯•...")
    print("=" * 60)

    try:
        await test_memory_manager()
        await test_task_list_manager()
        await test_planning_files()
        await test_hooks()
        await test_state_persistence()
        await test_base_agent_extensions()

        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼SuperAgent v3.3 åŠŸèƒ½éªŒè¯æˆåŠŸ")
        print("=" * 60)
        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1)


# ============================================================================
# ä»¥ä¸‹æ˜¯ v3.3 åŒè½¨è´¨é‡ä¿éšœ (æ–¹æ¡ˆA + æ–¹æ¡ˆB) çš„ç«¯åˆ°ç«¯æµ‹è¯•
# ============================================================================

def test_dual_mode_qa_e2e():
    """åŒè½¨è´¨é‡ä¿éšœç«¯åˆ°ç«¯æµ‹è¯•"""
    from pathlib import Path
    import sys

    print("\n" + "=" * 70)
    print("SuperAgent v3.3 åŒè½¨è´¨é‡ä¿éšœ - ç«¯åˆ°ç«¯æµ‹è¯•")
    print("=" * 70)

    # 1. æµ‹è¯• pytest_utils å·¥å…·æ¨¡å—
    print("\n[TEST 1] pytest_utils å·¥å…·æ¨¡å—")
    print("-" * 50)

    from core.pytest_utils import build_pytest_command, parse_pytest_output

    cmd1 = build_pytest_command()
    assert cmd1 == ["pytest", "-v", "--tb=short", "--disable-warnings"], f"Default cmd failed: {cmd1}"
    print("  âœ“ é»˜è®¤å‘½ä»¤æ„å»ºæ­£ç¡®")

    cmd2 = build_pytest_command(test_path="tests/unit", verbose=False)
    assert cmd2 == ["pytest", "tests/unit", "-q", "--tb=line", "--disable-warnings"]
    print("  âœ“ è‡ªå®šä¹‰è·¯å¾„å‘½ä»¤æ„å»ºæ­£ç¡®")

    sample_output = """
============================= test session starts =============================
tests/test_example.py::test_passed PASSED
tests/test_example.py::test_failed FAILED
tests/test_example.py::test_error ERROR
2 passed, 1 failed, 1 error in 0.05s
"""
    result = parse_pytest_output(sample_output)
    assert result["passed"] == 2
    assert result["failed"] == 1
    assert result["errors"] == 1
    assert result["success"] == False
    print("  âœ“ è¾“å‡ºè§£ææ­£ç¡® (å¤±è´¥åœºæ™¯)")

    success_output = "\n5 passed in 0.12s\n"
    success_result = parse_pytest_output(success_output)
    assert success_result["success"] == True
    print("  âœ… pytest_utils æ¨¡å—æµ‹è¯•é€šè¿‡")

    # 2. æµ‹è¯• TestRunner (æ–¹æ¡ˆA)
    print("\n[TEST 2] TestRunner - æ–¹æ¡ˆA (ä¸»å·¥ä½œæµé›†æˆ)")
    print("-" * 50)

    from core.test_runner import TestRunner, TestResult

    runner = TestRunner(project_root=Path("."), timeout=60)
    print(f"  âœ“ TestRunner åˆå§‹åŒ–æˆåŠŸ (timeout={runner._timeout}s)")

    sync_result = runner.run_pytest_sync(test_path="tests/test_dual_mode_qa.py", verbose=True)
    assert isinstance(sync_result, TestResult)
    assert sync_result.total_tests >= 0
    print(f"  âœ“ run_pytest_sync è¿”å› TestResult (passed={sync_result.passed}, failed={sync_result.failed})")

    result_dict = sync_result.to_dict()
    assert "success" in result_dict
    assert "total_tests" in result_dict
    print("  âœ“ to_dict() è½¬æ¢æ­£ç¡®")

    runner.set_timeout(120)
    assert runner._timeout == 120
    print("  âœ“ set_timeout() æ­£å¸¸å·¥ä½œ")

    print("  âœ… TestRunner æµ‹è¯•é€šè¿‡")

    # 3. æµ‹è¯• TestAdapter (æ–¹æ¡ˆB)
    print("\n[TEST 3] TestAdapter - æ–¹æ¡ˆB (ç‹¬ç«‹API)")
    print("-" * 50)

    from adapters.test_adapter import TestAdapter

    adapter = TestAdapter(project_root=Path("."), timeout=60)
    print(f"  âœ“ TestAdapter åˆå§‹åŒ–æˆåŠŸ (timeout={adapter._timeout}s)")

    sync_result = adapter.run_tests_sync(test_path="tests/test_dual_mode_qa.py")
    assert isinstance(sync_result, dict)
    assert "status" in sync_result
    assert "success" in sync_result
    print(f"  âœ“ run_tests_sync è¿”å›æ­£ç¡®ç»“æ„ (status={sync_result['status']})")

    adapter.set_timeout(120)
    assert adapter._timeout == 120
    print("  âœ“ set_timeout() æ­£å¸¸å·¥ä½œ")

    print("  âœ… TestAdapter æµ‹è¯•é€šè¿‡")

    # 4. æµ‹è¯• UnifiedAdapter é›†æˆ
    print("\n[TEST 4] UnifiedAdapter - å®Œæ•´æµç¨‹é›†æˆ")
    print("-" * 50)

    from adapters.unified_adapter import UnifiedAdapter

    unified = UnifiedAdapter(project_root=Path("."))
    print("  âœ“ UnifiedAdapter åˆå§‹åŒ–æˆåŠŸ")

    assert hasattr(unified, 'tester')
    assert isinstance(unified.tester, TestAdapter)
    print("  âœ“ tester å±æ€§æ­£ç¡®åˆå§‹åŒ–")

    assert hasattr(unified, 'run_tests')
    assert hasattr(unified, 'run_tests_sync')
    print("  âœ“ æµ‹è¯•æ–¹æ³•æ­£ç¡®æš´éœ²")

    assert hasattr(unified, 'execute_and_review_and_test')
    assert hasattr(unified, 'execute_and_review_and_test_sync')
    print("  âœ“ å®Œæ•´å·¥ä½œæµæ–¹æ³•æ­£ç¡®æš´éœ²")

    result = unified.run_tests_sync(test_path="tests/test_dual_mode_qa.py")
    assert result["status"] == "completed"
    assert result["success"] == True
    assert result["passed"] >= 21
    print(f"  âœ“ run_tests_sync å®é™…æ‰§è¡Œæµ‹è¯• (passed={result['passed']})")

    print("  âœ… UnifiedAdapter æµ‹è¯•é€šè¿‡")

    # 5. æµ‹è¯•é…ç½®é›†æˆ
    print("\n[TEST 5] é…ç½®é›†æˆæµ‹è¯•")
    print("-" * 50)

    from orchestration.models import TestingConfig, OrchestrationConfig

    config = TestingConfig()
    assert config.enabled == True
    assert config.timeout == 300
    print(f"  âœ“ TestingConfig é»˜è®¤å€¼æ­£ç¡® (enabled={config.enabled}, timeout={config.timeout})")

    custom_config = TestingConfig(enabled=False, test_path="tests/unit", timeout=600)
    assert custom_config.enabled == False
    assert custom_config.timeout == 600
    print("  âœ“ TestingConfig è‡ªå®šä¹‰å€¼æ­£ç¡®")

    orch_config = OrchestrationConfig()
    assert hasattr(orch_config, 'testing')
    assert isinstance(orch_config.testing, TestingConfig)
    print("  âœ“ OrchestrationConfig.testing é›†æˆæ­£ç¡®")

    print("  âœ… é…ç½®é›†æˆæµ‹è¯•é€šè¿‡")

    # 6. æ¨¡å—å¯¼å‡ºæµ‹è¯•
    print("\n[TEST 6] æ¨¡å—å¯¼å‡ºæµ‹è¯•")
    print("-" * 50)

    from adapters import TestAdapter as TA1
    from adapters.test_adapter import TestAdapter as TA2
    from core.test_runner import TestRunner as TR1
    from core.test_runner import TestResult
    from core.pytest_utils import build_pytest_command as bpc

    assert TA1 is TA2
    print("  âœ“ TestAdapter å¯¼å‡ºæ­£ç¡®")

    from SuperAgent import TestRunner as SA_TR
    from SuperAgent import TestAdapter as SA_TA
    print("  âœ“ SuperAgent ç®€æ´å¯¼å…¥åŒ…å« TestRunner å’Œ TestAdapter")

    print("  âœ… æ¨¡å—å¯¼å‡ºæµ‹è¯•é€šè¿‡")

    # 7. å®é™…æ‰§è¡Œæµ‹è¯•
    print("\n[TEST 7] å®Œæ•´å·¥ä½œæµå®é™…æ‰§è¡Œæµ‹è¯•")
    print("-" * 50)

    print("\n  [7.1] æ–¹æ¡ˆB: ç‹¬ç«‹æµ‹è¯•æ‰§è¡Œ")
    test_result = unified.run_tests_sync(test_path="tests/test_dual_mode_qa.py")
    assert test_result["status"] == "completed"
    assert test_result["success"] == True
    print(f"      âœ“ ç‹¬ç«‹æµ‹è¯•æ‰§è¡ŒæˆåŠŸ: {test_result['passed']} passed")

    print("\n  [7.2] æ–¹æ¡ˆB: å¿«é€Ÿæµ‹è¯•")
    quick_result = adapter.run_quick_tests()
    print(f"      âœ“ å¿«é€Ÿæµ‹è¯•å®Œæˆ: status={quick_result['status']}")

    print("\n  [7.3] æ–¹æ¡ˆA: TestRunner å®é™…æ‰§è¡Œ")
    runner_result = runner.run_pytest_sync(test_path="tests/test_dual_mode_qa.py", verbose=False)
    assert runner_result.success == True
    assert runner_result.passed >= 21
    print(f"      âœ“ TestRunner æ‰§è¡ŒæˆåŠŸ: {runner_result.passed} passed")

    print("  âœ… å®Œæ•´å·¥ä½œæµæµ‹è¯•é€šè¿‡")

    # 8. å¼‚å¸¸å¤„ç†æµ‹è¯•
    print("\n[TEST 8] å¼‚å¸¸å¤„ç†æµ‹è¯•")
    print("-" * 50)

    error_result = adapter.run_tests_sync(test_path="tests/nonexistent_file.py")
    assert error_result["status"] == "completed"
    assert "output" in error_result
    print("  âœ“ ä¸å­˜åœ¨çš„æµ‹è¯•æ–‡ä»¶å¤„ç†æ­£ç¡®")

    print("  âœ… å¼‚å¸¸å¤„ç†æµ‹è¯•é€šè¿‡")

    print("\n" + "=" * 70)
    print("ğŸ‰ æ‰€æœ‰ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡!")
    print("=" * 70)

    return True


if __name__ == "__main__":
    try:
        test_dual_mode_qa_e2e()
        print("\nåŒè½¨è´¨é‡ä¿éšœç«¯åˆ°ç«¯æµ‹è¯•: SUCCESS")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
